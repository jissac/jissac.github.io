<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>James Issac</title>
    <link>https://jamesis.me/</link>
      <atom:link href="https://jamesis.me/index.xml" rel="self" type="application/rss+xml" />
    <description>James Issac</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>2020 James Issac</copyright><lastBuildDate>Thu, 06 Feb 2020 21:06:26 -0500</lastBuildDate>
    <image>
      <url>https://jamesis.me/img/icon-192.png</url>
      <title>James Issac</title>
      <link>https://jamesis.me/</link>
    </image>
    
    <item>
      <title>Grouping in Pandas and PySpark</title>
      <link>https://jamesis.me/post/grouping/</link>
      <pubDate>Thu, 06 Feb 2020 21:06:26 -0500</pubDate>
      <guid>https://jamesis.me/post/grouping/</guid>
      <description>&lt;p&gt;Grouping is a fundamental idea in data science - one that helps the data scientist glean overall insights from seemingly disjointed data elements. In this article, we&amp;rsquo;ll take a look at how to group data elements using both the Python Pandas library as well as the distributed computing framework PySpark.&lt;/p&gt;
&lt;h2 id=&#34;grouping-in-pandas&#34;&gt;Grouping in Pandas&lt;/h2&gt;
&lt;p&gt;In the Python library Pandas, the concept of grouping is often mentioned in the overall context of the term &amp;ldquo;split-combine-apply&amp;rdquo;.&lt;/p&gt;
&lt;h2 id=&#34;grouping-in-pyspark&#34;&gt;Grouping in PySpark&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Clustering: Birds of a Feather Flock Together</title>
      <link>https://jamesis.me/post/clustering/</link>
      <pubDate>Tue, 22 Oct 2019 15:51:20 -0500</pubDate>
      <guid>https://jamesis.me/post/clustering/</guid>
      <description>&lt;p&gt;The task of grouping data points into groups (clusters) such that points in a group are more ‘similar’ to each other than to points outside the group is called clustering. But how does one know if a data point is similar to another point or not? This act of defining similarity is what distinguishes various clustering methods from each other — K-Means defines similarity by the closeness of a data point to the centroid of the clusters while DBSCAN defines similarity by grouping together data points that are within the same density region.
In this article, we’ll take a look at these two clustering methods that are often used in unsupervised machine learning and implement them in Python. So let’s get started!&lt;/p&gt;
&lt;h2 id=&#34;k-means&#34;&gt;K-Means&lt;/h2&gt;
&lt;p&gt;The K-Means clustering algorithm is a type of hard clustering — a data point can belong only to one cluster completely (as opposed to a soft clustering method in which each data point is assigned a probability or likelihood to be in a given cluster).
The K-Means algorithm iterates through the following steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Specify the desired number of clusters K&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Initialize K cluster centroids&lt;/strong&gt; in some fashion. The centroids are not necessarily data points themselves but can be generated within the data domain.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Assign each data point to its closest cluster centroid&lt;/strong&gt;. ‘Closest’ is defined by minimizing the Euclidean distance (or L2 norm), which is the square root of the sum of the squared vector values (think Pythagorean theorem in 2D).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reassign K cluster centroids&lt;/strong&gt; by calculating the mean of all points within each cluster and setting the new centroid values as that.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Calculate the distance&lt;/strong&gt; each centroid changed from its previous value&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Repeat steps 3, 4, and 5&lt;/strong&gt; until the distance each centroid changes drops below a predefined threshold or until a predefined number of iterations has been reached.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;k-means-assumptions-and-limitations&#34;&gt;K-Means Assumptions and Limitations&lt;/h3&gt;
&lt;p&gt;It is important to note that K-Means reduces the within-cluster sum of squares, or the variance of the observations within each cluster. In other words, a cluster that has a small sum of squares is more compact than one with a large sum of squares. Furthermore, as the number of observations within a cluster increases, the sum of squares becomes larger. As a result, &lt;strong&gt;K-Means works best when the data points are organized in convex, spherical clusters and contain roughly the same number of points within each cluster&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;In the figure below, whereas K-Means struggles clustering into two groups with the data points on the left, transforming the dataset from Cartesian to polar coordinates results in reasonable cluster assignments. Therefore, &lt;strong&gt;an important insight is to visualize and understand your dataset before applying a clustering algorithm to it&lt;/strong&gt;.
&lt;img src=&#34;k-means.png&#34; alt=&#34;Source: http://varianceexplained.org/r/kmeans-free-lunch/&#34;&gt; &lt;em&gt;Source: &lt;a href=&#34;http://varianceexplained.org/r/kmeans-free-lunch/&#34;&gt;http://varianceexplained.org/r/kmeans-free-lunch/&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Also, since K-Means requires the number of clusters to be predefined, choosing the correct value for K is important but also difficult, especially when you cannot visualize all the dimensions in your dataset. However, you can use either the &lt;a href=&#34;https://en.wikipedia.org/wiki/Elbow_method_(clustering)&#34;&gt;Elbow Method&lt;/a&gt; or the &lt;a href=&#34;https://en.wikipedia.org/wiki/Silhouette_(clustering)&#34;&gt;Silhouette Method&lt;/a&gt; to determine the best choice of K when the number of clusters to choose is not clear.&lt;/p&gt;
&lt;h2 id=&#34;dbscan&#34;&gt;DBSCAN&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.aaai.org/Papers/KDD/1996/KDD96-037.pdf&#34;&gt;Density-Based Spatial Clustering of Applications with Noise&lt;/a&gt; or DBSCAN, for short, was proposed in 1996 and organizes clusters based on the density of points and unlike K-Means, determines the number of clusters to be generated without user input. Furthermore, DBSCAN allows us to classify noise (unlike K-Means) by defining noise as areas with lower density points than clusters. For example, whereas K-Means struggles with the following distribution, DBSCAN is able to correctly identify the clusters based on the density of points.
&lt;img src=&#34;smiley.png&#34; alt=&#34;Source: https://www.naftaliharris.com/blog/visualizing-dbscan-clustering/&#34;&gt;&lt;em&gt;Source: &lt;a href=&#34;https://www.naftaliharris.com/blog/visualizing-dbscan-clustering/&#34;&gt;https://www.naftaliharris.com/blog/visualizing-dbscan-clustering/&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;There are two key ideas / hyperparameters in DBSCAN — &lt;em&gt;MinPts&lt;/em&gt; and &lt;em&gt;Eps&lt;/em&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;For each point in a cluster, there have to be at least a specified minimum number of points (MinPts) in its neighborhood, i.e. the density in the neighborhood has to exceed some threshold. The parameter MinPts primarily controls how tolerant the algorithm is to noise.&lt;/li&gt;
&lt;li&gt;Neighborhood is defined as the space around a point (Eps) and its shape is determined by the chosen distance function, i.e. when using the Manhattan distance in 2D space, the shape of the neighborhood is rectangular. Similarly to K-Means, the most common distance function used for DBSCAN is Euclidean distance.
Using these two hyperparamters, DBSCAN categorizes the data points into three categories: core points, or points inside of the cluster, border points, or points on the edge of the cluster, and noise, or points that do not belong to any cluster.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;dbscan-assumptions-and-limitations&#34;&gt;DBSCAN Assumptions and Limitations&lt;/h3&gt;
&lt;p&gt;Because the parameter Eps controls the local neighborhood of the data points and influences cluster assignment, it is crucial to choose it appropriately and it usually cannot be left at the default value. If set too large, clusters will merge into one another, eventually returning one cluster if Eps is large enough. If set too small, most data points will not be clustered at all or be categorized as noise. The importance of choosing the right value of Eps is demonstrated in the figure below.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;eps-compare.png&#34; alt=&#34;Effect of varying epsilson parameter&#34;&gt;&lt;/p&gt;
&lt;p&gt;Furthermore, DBSCAN struggles with datasets containing clusters with largely varying densities, as the parameters Eps and MinPts cannot be customized for each cluster. And for high-dimensional data, the standard choice of Euclidean distance suffers, which makes it challenging to find an appropriate value for Eps. Therefore, it is worth repeating as for K-Means, &lt;strong&gt;it is important to visualize and understand your dataset before applying a clustering algorithm to it&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 id=&#34;implementation&#34;&gt;Implementation&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/jissac/ScratchML/blob/master/Clustering.ipynb&#34;&gt;Refer to the following notebook&lt;/a&gt; for a from-scratch Python implementation of K-Means and DBSCAN, followed by a comparison with the popular Scikit-Learn implementation of the algorithms. Hope it helps you understand the inner workings of these two algorithms and the assumptions behind each!&lt;/p&gt;
&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;
&lt;p&gt;In conclusion, K-Means and DBSCAN are two powerful algorithms to use when you have an unlabeled dataset that needs to be clustered into groups. However, &lt;strong&gt;remember to be mindful of the assumptions underlying the model you choose&lt;/strong&gt; — understanding your dataset and preprocessing it are essential in order to get correct predictions from your models. Also, be sure to read the Scikit-Learn clustering documentation to learn about other clustering algorithms!&lt;/p&gt;
&lt;h2 id=&#34;references--helpful-links&#34;&gt;References / Helpful Links:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://scikit-learn.org/stable/modules/clustering.html&#34;&gt;https://scikit-learn.org/stable/modules/clustering.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://support.minitab.com/en-us/minitab/18/help-and-how-to/modeling-statistics/multivariate/how-to/cluster-k-means/interpret-the-results/all-statistics-and-graphs/&#34;&gt;https://support.minitab.com/en-us/minitab/18/help-and-how-to/modeling-statistics/multivariate/how-to/cluster-k-means/interpret-the-results/all-statistics-and-graphs/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.aaai.org/Papers/KDD/1996/KDD96-037.pdf&#34;&gt;https://www.aaai.org/Papers/KDD/1996/KDD96-037.pdf&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Essential SQL</title>
      <link>https://jamesis.me/post/essential-sql/</link>
      <pubDate>Fri, 23 Nov 2018 16:22:10 -0500</pubDate>
      <guid>https://jamesis.me/post/essential-sql/</guid>
      <description>&lt;p&gt;Given the rise of ‘big-data’, effectively managing and working with that stored data becomes very important — you’re only able to ask better questions if you can quickly glean insights from the data you have.
Unlike smaller datasets that can fit easily into a local computer’s hard disk, big data by definition won’t fit into local storage and must instead be stored in a database — a structured set of information that can be queried, accessed, and updated in various ways.
A database management system (DBMS) is the software that the end-user interacts with to use the database. To access the DBMS and database, we use a language called Structured Query Language (SQL) which provides a codified way to communicate with the DBMS and modify data stored in the database. SQL can be used to query and process data from DBMS tools like SQLite or Postgres or from the Hadoop Distributed File System (HDFS) using SQL-like languages like HiveQL or Spark SQL, for example.&lt;/p&gt;
&lt;h2 id=&#34;basic-sql-query&#34;&gt;Basic SQL Query&lt;/h2&gt;
&lt;p&gt;In the SQL workflow, most of the time is spent writing requests (queries) that fetch a subset of or edit values from tables contained in the database. An example query looks like:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-SQL&#34; data-lang=&#34;SQL&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;       
&lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;table_name&lt;/span&gt;         
&lt;span style=&#34;color:#66d9ef&#34;&gt;LIMIT&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;;     
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Breaking down the statement above,      &lt;br&gt;
&lt;code&gt;SELECT *:&lt;/code&gt; selects which columns we want (* denotes all the columns)   &lt;br&gt;
&lt;code&gt;FROM table_name:&lt;/code&gt; the table we want to query (&lt;code&gt;table_name&lt;/code&gt;)     &lt;br&gt;
&lt;code&gt;LIMIT 5:&lt;/code&gt; the number of rows we want (first 5 in this case)&lt;/p&gt;
&lt;p&gt;To filter rows by a specific criteria, we use the &lt;code&gt;WHERE&lt;/code&gt; statement.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-SQL&#34; data-lang=&#34;SQL&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; 
&lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;table_name&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;WHERE&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;column_name&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;.&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;LIMIT&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;A &lt;code&gt;WHERE&lt;/code&gt; statement contains three things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The column name we want to filter on (column_name)&lt;/li&gt;
&lt;li&gt;A comparison operator (&amp;lt;,≤,&amp;gt;,≥,=,!=)&lt;/li&gt;
&lt;li&gt;The value we want the database to compare each value to (0.5 in this case)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We can also use a conditional operator like &lt;code&gt;AND&lt;/code&gt; or &lt;code&gt;OR&lt;/code&gt; to further filter our results and the &lt;code&gt;ORDER BY&lt;/code&gt; clause to order our results by ascending (&lt;code&gt;ASC&lt;/code&gt;) or descending (&lt;code&gt;DESC&lt;/code&gt;) order.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-SQL&#34; data-lang=&#34;SQL&#34;&gt;...
&lt;span style=&#34;color:#66d9ef&#34;&gt;WHERE&lt;/span&gt; [condition1] &lt;span style=&#34;color:#66d9ef&#34;&gt;AND&lt;/span&gt; [condition2]
&lt;span style=&#34;color:#66d9ef&#34;&gt;ORDER&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;BY&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;column_name&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;DESC&lt;/span&gt;;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;summary-statistics&#34;&gt;Summary Statistics&lt;/h2&gt;
&lt;p&gt;We can use SQL to code and execute summary statistics like mean and standard deviation and aggregate functions like count, max, and min. We can also use the alias syntax AS to temporarily rename a table or a column in a query and the &lt;code&gt;DISTINCT&lt;/code&gt; keyword in conjunction with the &lt;code&gt;SELECT&lt;/code&gt; statement to fetch only the unique records and disregard duplicates. The query below, for example, aggregates all the unique values of &lt;code&gt;col1&lt;/code&gt; in &lt;code&gt;table_name&lt;/code&gt;(which has been renamed as &lt;code&gt;table_alias_name&lt;/code&gt;), renames &lt;code&gt;col1&lt;/code&gt; as &lt;code&gt;col_alias_name&lt;/code&gt; and returns the row count.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-SQL&#34; data-lang=&#34;SQL&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;COUNT&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;DISTINCT&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;column_name&lt;/span&gt;)) &lt;span style=&#34;color:#66d9ef&#34;&gt;AS&lt;/span&gt; col_alias_name
&lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;table_name&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;AS&lt;/span&gt; table_alias_name
&lt;span style=&#34;color:#66d9ef&#34;&gt;WHERE&lt;/span&gt; [condition1];
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;grouping&#34;&gt;Grouping&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;GROUP BY&lt;/code&gt; clause allows us to further compute summary statistics by combining identical data into groups. It follows the &lt;code&gt;WHERE&lt;/code&gt; clause and precedes the &lt;code&gt;ORDER BY&lt;/code&gt; clause. To place conditions and filter on groups created by the &lt;code&gt;GROUP BY&lt;/code&gt; clause, we can use the &lt;code&gt;HAVING&lt;/code&gt; clause.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-SQL&#34; data-lang=&#34;SQL&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; col1_name, ROUND(&lt;span style=&#34;color:#66d9ef&#34;&gt;AVG&lt;/span&gt;(col2_name) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;AVG&lt;/span&gt;(col3_name), &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;AS&lt;/span&gt; percentage 
&lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;table_name&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;WHERE&lt;/span&gt; [condition1]
&lt;span style=&#34;color:#66d9ef&#34;&gt;GROUP&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;BY&lt;/span&gt; col1_name 
&lt;span style=&#34;color:#66d9ef&#34;&gt;HAVING&lt;/span&gt; percentage &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; .&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;ORDER&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;BY&lt;/span&gt; percentage;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Oftentimes it’s useful to know the type of each column when doing arithmetic — this can be done using the &lt;code&gt;PRAGMA TABLE_INFO(table_name)&lt;/code&gt; command. And if we want to cast a column as a specific type, we can use the &lt;code&gt;CAST&lt;/code&gt; clause:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-SQL&#34; data-lang=&#34;SQL&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;CAST&lt;/span&gt;(col1_name &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; Float) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;CAST&lt;/span&gt;(col2_name &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; Float) &lt;span style=&#34;color:#66d9ef&#34;&gt;AS&lt;/span&gt; alias_name
&lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;table_name&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;LIMIT&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;subqueries&#34;&gt;Subqueries&lt;/h2&gt;
&lt;p&gt;Unlike imperative, object-oriented programming languages like Python or C++, SQL doesn’t have variables you can define and use. Instead, SQL is a declarative programming language where we focus on expressing computations instead of defining how to do them. So since we can’t assign variables, we’ll have to use something called subqueries, or a query nested within another query. Subqueries must be enclosed within parenthesis and can be used within the &lt;code&gt;WHERE&lt;/code&gt; clause:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-SQL&#34; data-lang=&#34;SQL&#34;&gt;...
&lt;span style=&#34;color:#66d9ef&#34;&gt;WHERE&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;column_name&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;OPERATOR&lt;/span&gt;
   (&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;AVG&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;column_name&lt;/span&gt;)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;table_name&lt;/span&gt;);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;or within the &lt;code&gt;SELECT&lt;/code&gt; clause:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-SQL&#34; data-lang=&#34;SQL&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;COUNT&lt;/span&gt;(&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;), (&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;COUNT&lt;/span&gt;(&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;table_name&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;table_name&lt;/span&gt; 
&lt;span style=&#34;color:#66d9ef&#34;&gt;WHERE&lt;/span&gt; [condition];
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;or within both the &lt;code&gt;WHERE&lt;/code&gt; and &lt;code&gt;SELECT&lt;/code&gt; clauses:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-SQL&#34; data-lang=&#34;SQL&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;COUNT&lt;/span&gt;(&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;), (&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;COUNT&lt;/span&gt;(&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;table_name&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;table_name&lt;/span&gt; 
&lt;span style=&#34;color:#66d9ef&#34;&gt;WHERE&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;column_name&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;OPERATOR&lt;/span&gt;
   (&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;AVG&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;column_name&lt;/span&gt;)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;table_name&lt;/span&gt;);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;joining-data&#34;&gt;Joining Data&lt;/h2&gt;
&lt;p&gt;Data will often be spread across multiple tables and in those cases, joining datasets together is often the first thing to do before doing analysis. In SQL, the JOIN clause combines data from two tables by using values common to each. The most common way to join data using SQL is by using an &lt;code&gt;INNER JOIN&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-SQL&#34; data-lang=&#34;SQL&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; 
&lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt; table_name1
&lt;span style=&#34;color:#66d9ef&#34;&gt;INNER&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;JOIN&lt;/span&gt; table_name2
&lt;span style=&#34;color:#66d9ef&#34;&gt;ON&lt;/span&gt; [join_constraint]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;An &lt;code&gt;INNER JOIN&lt;/code&gt; won’t include any rows where there isn’t a mutual match from both tables — in this way we could end up losing data that is only present in one table. One solution is to use a &lt;code&gt;LEFT JOIN&lt;/code&gt;, which includes all the rows from the left (first) table that are not selected with the &lt;code&gt;INNER JOIN&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-SQL&#34; data-lang=&#34;SQL&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;SELECT&lt;/span&gt; col5_name 
&lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt; table_name1
&lt;span style=&#34;color:#66d9ef&#34;&gt;LEFT&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;JOIN&lt;/span&gt; table_name2
&lt;span style=&#34;color:#66d9ef&#34;&gt;ON&lt;/span&gt; table_name2.col1_name &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; table_name1.col3_name
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The figure below shows the difference between &lt;code&gt;INNER JOIN&lt;/code&gt; and &lt;code&gt;LEFT JOIN&lt;/code&gt;.
&lt;img src=&#34;joins.png&#34; alt=&#34;joins&#34;&gt;&lt;em&gt;Source: &lt;a href=&#34;http://www.sql-join.com/sql-join-types/&#34;&gt;http://www.sql-join.com/sql-join-types/&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;creating-tables&#34;&gt;Creating Tables&lt;/h2&gt;
&lt;p&gt;To add tables in a database, we use the &lt;code&gt;CREATE TABLE&lt;/code&gt; clause.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-SQL&#34; data-lang=&#34;SQL&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;CREATE&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;TABLE&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;table_name&lt;/span&gt; (
    column1_name column1_type,
    column2_name column2_type,
    column3_name column3_type,
    ...
);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Data types define what type of data a column can contain. There are many different types you can choose from including, &lt;code&gt;TEXT&lt;/code&gt;, &lt;code&gt;NUMERIC&lt;/code&gt;, &lt;code&gt;INTEGER&lt;/code&gt;, &lt;code&gt;FLOAT&lt;/code&gt;, &lt;code&gt;BLOB&lt;/code&gt;, many others.
If you make a mistake creating a table using the command &lt;code&gt;DROP TABLE table_name&lt;/code&gt; will delete the created table. You can use the dot command &lt;code&gt;.schema table_name&lt;/code&gt; to view the schema for the table you created and you can use the &lt;code&gt;ALTER&lt;/code&gt; command to add, delete, or modify columns in an existing table.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;I hope this gets you started on your SQL journey. As always, there’s much more to learn and queries can become quite complicated. However, these basics will guide you as you practice — so here’s to more querying!&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;resources&#34;&gt;Resources:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;These are my notes from the excellent DataQuest learning track. Check them out and subscribe at &lt;a href=&#34;http://www.dataquest.io&#34;&gt;www.dataquest.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;For a complete list of SQL commands, check out: &lt;a href=&#34;https://www.tutorialspoint.com/sqlite&#34;&gt;https://www.tutorialspoint.com/sqlite&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;A SQL style guide: &lt;a href=&#34;https://www.sqlstyle.guide/&#34;&gt;https://www.sqlstyle.guide/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Understanding Deep Neural Networks from First Principles: Logistic Regression</title>
      <link>https://jamesis.me/post/deep-learning-lr/</link>
      <pubDate>Wed, 18 Apr 2018 16:41:18 -0500</pubDate>
      <guid>https://jamesis.me/post/deep-learning-lr/</guid>
      <description>&lt;p&gt;Over the past few decades, the digitization of our society has led to massive amounts of data being stored. Combining this increase in the scale of stored information with advances in hardware computational power and algorithmic innovations, the field of artificial intelligence (AI) has jumped into the spotlight as machines seem to possess the ‘magical’ ability to learn without being told explicitly what to do.&lt;/p&gt;
&lt;p&gt;Examples of impressive feats performed by machines include: AlphaGo defeating 9dan rank Go champion Lee Sedol, self-driving cars navigating city streets, and a computer learning to beat Super Mario World by itself. At the heart of such systems have been algorithms called deep neural networks that can model the non-linearities inherently present in image, audio, and video data.&lt;/p&gt;
&lt;p&gt;So… why is this important?&lt;/p&gt;
&lt;p&gt;My goal in this article is to convince you that these recent advances in AI aren’t the purview of a select few but that if you’re interested, you too can learn about and contribute to this amazing field. We’ll start by peeling back the layers of abstraction surrounding deep neural networks and begin by using logistic regression as our first principle starting point (had to start somewhere!). I’ll assume you have basic knowledge of matrix math(&lt;a href=&#34;https://www.youtube.com/watch?v=LyGKycYT2v0&#34;&gt;dot products&lt;/a&gt;), calculus (&lt;a href=&#34;https://www.youtube.com/watch?v=AXqhWeUEtQU&#34;&gt;partial derivatives&lt;/a&gt;), probability theory (&lt;a href=&#34;https://www.youtube.com/watch?v=JGeTcRfKgBo&#34;&gt;conditional probability&lt;/a&gt;), and &lt;a href=&#34;https://www.codecademy.com/learn/learn-python&#34;&gt;Python programming&lt;/a&gt;. If not, do not fear! Follow the links above and keep learning — if you have an internet connection and an unyielding thirst for knowledge, be patient with yourself and you’ll soon be slaying all the proverbial giants. I’ve linked references and resources at the end as learning aids — after all, standing on shoulders is a great way to see further ahead.&lt;/p&gt;
&lt;p&gt;So, by understanding how logistic regression can be modeled as a single neuron you’ll understand fundamental deep learning concepts like &lt;strong&gt;weights&lt;/strong&gt;, &lt;strong&gt;activation functions&lt;/strong&gt;, &lt;strong&gt;loss functions&lt;/strong&gt;, &lt;strong&gt;gradient descent&lt;/strong&gt;, &lt;strong&gt;learning rate&lt;/strong&gt;, &lt;strong&gt;training&lt;/strong&gt;, &lt;strong&gt;forward and backward propagation&lt;/strong&gt;, and &lt;strong&gt;prediction&lt;/strong&gt;. You’ll then be able to move on to more advanced topics that link many neurons together into deep networks — like Convolutional Neural Nets (CNNs), Generative Adversarial Nets (GANs), and Recurrent Neural Nets(RNNs), to name a few. So let’s get started!&lt;/p&gt;
&lt;h2 id=&#34;a-neuron&#34;&gt;A Neuron&lt;/h2&gt;
&lt;p&gt;Let’s use the word ‘neuron’ to describe a function that looks like this:
&lt;img src=&#34;neuron.png&#34; alt=&#34;neuron&#34;&gt;&lt;/p&gt;
&lt;p&gt;You have inputs and you have an output (this a 1-layer neural net — by convention we don’t count the initial raw inputs as a layer). If you squint hard enough, it even sort of looks like a &lt;a href=&#34;http://s4.thingpic.com/images/E6/BdHJAWutQ3E5zkvcgFz8Kk8x.png&#34;&gt;human neuron&lt;/a&gt;. This function is defined as a weighted sum of its inputs — we multiply the inputs &lt;em&gt;&lt;strong&gt;x&lt;/strong&gt;&lt;/em&gt; by variables &lt;em&gt;&lt;strong&gt;w&lt;/strong&gt;&lt;/em&gt; called weights to get the output. You can think of weights as the strengths of the connections between input and output — for example, if &lt;em&gt;w1&lt;/em&gt; has a higher value than &lt;em&gt;w2&lt;/em&gt;, that implies that the input x1 influences the output more than &lt;em&gt;x2&lt;/em&gt; does. The value &lt;em&gt;b&lt;/em&gt; is called the bias term (it isn’t multiplied by a weight) and is responsible for shifting the function so that it’s not constrained to the origin. Representing the function in matrix form yields:
&lt;img src=&#34;neuron-matrix-form.png&#34; alt=&#34;neuron-matrix-form&#34;&gt;&lt;/p&gt;
&lt;p&gt;The shape of the matrix &lt;em&gt;w&lt;/em&gt; is determined by the number of units in the layer you’re mapping to and the number of units in the layer you’re mapping from— hence the shape [1 x 3] because the output layer has 1 unit and the input layer has 3 units (not counting the bias term). This looks a lot like the equation for a line:
&lt;img src=&#34;line-eqn.png&#34; alt=&#34;line-eqn&#34;&gt;&lt;/p&gt;
&lt;p&gt;However, the strength of a neural network lies in its ability to model complex nonlinearities. Even if you link many of these units together in a deep network (the green units are called hidden layers) as shown below,&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;3-layer-network.png&#34; alt=&#34;3 layer neural network&#34;&gt;&lt;/p&gt;
&lt;p&gt;the composition of many linear functions is itself a linear function. So our journey is not yet complete — how can the function model the non-linear patterns present in the input data in such a way that it can predict, with high accuracy, similar patterns in data it has never seen before?&lt;/p&gt;
&lt;p&gt;To model a non-linear problem, we will need to introduce a nonlinear activation function.&lt;/p&gt;
&lt;h2 id=&#34;the-sigmoid-function&#34;&gt;The Sigmoid Function&lt;/h2&gt;
&lt;p&gt;Let’s define a function called sigmoid. It has a probability distribution that looks like this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;sigmoid.png&#34; alt=&#34;Source: https://commons.wikimedia.org/w/index.php?curid=4310325&#34;&gt;&lt;/p&gt;
&lt;p&gt;The equation for a sigmoid function is:
&lt;img src=&#34;sigmoid-eqn.png&#34; alt=&#34;sigmoid eqn&#34;&gt;
The sigmoid activation function converts its input to a value between 0 and 1 — as z increases towards positive infinity the output gets closer to 1, and as z decreases towards negative infinity the output gets closer to 0. Going back to our example of a single neuron, we can feed our function &lt;em&gt;z = wx + b&lt;/em&gt; as an input to the sigmoid activation function, which yields:
&lt;img src=&#34;neuron-sigmoid-eqn.png&#34; alt=&#34;sigmoid neuron eqn&#34;&gt;
Where the variable A represents the sigmoid activation function. Showing it pictorially using our single-layer representation of a neuron:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;neuron-sigmoid.png&#34; alt=&#34;Applying the sigmoid activation function&#34;&gt;
So how is this valuable? Stacking nonlinearities on nonlinearities in a deep network allows us to model very complex relationships between inputs and outputs. Even in the case of our single neuron above, let’s see how adding a nonlinear activation function can be useful.&lt;/p&gt;
&lt;h2 id=&#34;logistic-regression&#34;&gt;Logistic Regression&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Logistic_regression&#34;&gt;Logistic regression&lt;/a&gt; is a binary classification method. For example, after being trained on images of cats and dogs and then being given a picture that it has never seen before of a cat (y=0) or a dog (y=1), can the machine predict the correct type? As we’ll see, even a simple algorithm like logistic regression can do surprisingly well.
We want to model a function that can take in any number of inputs and constrain the output to be between 0 and 1. Where have we seen that before? You guessed it — our humble neuron, armed with the sigmoid activation function, boldly comes in to save the day! Now is there a way to measure how good our predicted output is compared to the true label?&lt;/p&gt;
&lt;h3 id=&#34;loss-function-and-cost-function&#34;&gt;Loss Function and Cost Function&lt;/h3&gt;
&lt;p&gt;Let’s define &lt;em&gt;y&lt;/em&gt; as the true label (y = 0 or y = 1) and &lt;em&gt;y_hat&lt;/em&gt; as the predicted output (or the probability that y = 1 given inputs w and x). Therefore, the probability that y = 0 given inputs &lt;em&gt;w&lt;/em&gt; and &lt;em&gt;x&lt;/em&gt; is (1 - &lt;em&gt;y_hat&lt;/em&gt;), as shown below.
&lt;img src=&#34;loss-prob.png&#34; alt=&#34;Loss probability&#34;&gt;
&lt;a href=&#34;http://cs229.stanford.edu/notes/cs229-notes1.pdf&#34;&gt;After doing some derivations&lt;/a&gt; based on the equations above, we can define the logistic loss function for a set of inputs in a single training example to be:
&lt;img src=&#34;log-loss.png&#34; alt=&#34;Log loss&#34;&gt;&lt;/p&gt;
&lt;p&gt;The goal of the loss function is to minimize the error between the predicted and desired output and thus arrive at an optimal solution for one training example. However, to get useful results we need to take the average of the loss function over an entire training set that contains many examples (for a total of m examples). This is defined as the cost function &lt;em&gt;&lt;strong&gt;J(w,b)&lt;/strong&gt;&lt;/em&gt; and we’ll find the parameters &lt;em&gt;&lt;strong&gt;w&lt;/strong&gt;&lt;/em&gt; and &lt;em&gt;&lt;strong&gt;b&lt;/strong&gt;&lt;/em&gt; that minimize the overall cost function:
&lt;img src=&#34;cost-fn.png&#34; alt=&#34;cost fn&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;gradient-descent&#34;&gt;Gradient Descent&lt;/h3&gt;
&lt;p&gt;Plotting the cost function &lt;em&gt;&lt;strong&gt;J(w,b)&lt;/strong&gt;&lt;/em&gt; yields a graph that looks like this:
&lt;img src=&#34;gradient-descent.png&#34; alt=&#34;gradient-descent&#34;&gt;
One of the reasons we use this cost function for logistic regression is that it’s a convex function with a single global optimum. Imagine rolling a ball down the bowl-shaped function — it would settle at the bottom; similarly, to find the minimum of the cost function, we need to get to the lowest point. To do that, we can start from anywhere on the function and iteratively move down in the direction of the steepest slope, adjusting the values of w and b that lead us to the minimum. The formulas are:
&lt;img src=&#34;gd-formula.png&#34; alt=&#34;gd-formula&#34;&gt;
In these two equations, the partial derivatives &lt;em&gt;dw&lt;/em&gt; and &lt;em&gt;db&lt;/em&gt; represent the effect that a change in &lt;em&gt;w&lt;/em&gt; and &lt;em&gt;b&lt;/em&gt; have on the cost function, respectively. By finding the slope and taking the negative of that slope, we ensure that we will always move in the direction of the minimum. To get a better understanding, let’s see this graphically for &lt;em&gt;dw&lt;/em&gt;:
&lt;img src=&#34;gd-graph.png&#34; alt=&#34;gd-graph&#34;&gt;
When the derivative term is positive, we move in the opposite direction towards a decreasing value of w and when the derivative is negative we move in the direction of increasing w, thereby ensuring that we’re always moving toward the minimum.&lt;/p&gt;
&lt;p&gt;The alpha term in front of the partial derivative is called the learning rate and is a measure of how big a step to take at each iteration. The choice of learning parameters is an important one — too small and the model will take an undue amount of time to find the minimum, too large and the model might overshoot the minimum and fail to converge.&lt;/p&gt;
&lt;p&gt;Gradient descent is the essence of the learning process — through it the machine learns what values of weights and biases minimize the cost function. It does this by iteratively comparing its predicted output for a set of data to the true output in a process called training.&lt;/p&gt;
&lt;h2 id=&#34;training-a-model&#34;&gt;Training a Model&lt;/h2&gt;
&lt;p&gt;An athlete is able to perform at a high level because of her extensive training — through repeated iterations and adjustments along the way, she’s able to figure out what works and what doesn’t. Similarly in supervised machine learning, given a set of inputs and output labels, a model learns the best combination of weights and biases that minimizes the overall cost function.&lt;/p&gt;
&lt;p&gt;(On a high level — when people talk about machine intelligence, it’s important to distinguish between this idea of learning as opposed to the more abstract idea of artificial consciousness, which is harder to quantify. The advanced feats we’ve seen machines do thus far have basically been examples of clever optimization techniques). So what does this learning process look like?&lt;/p&gt;
&lt;h3 id=&#34;forward-propagation&#34;&gt;Forward Propagation&lt;/h3&gt;
&lt;p&gt;First, weight and bias values are propagated forward through the model to arrive at a predicted output. At each neuron/node, the linear combination of the inputs is then multiplied by an activation function as described above— the sigmoid function in our example. This process by which weights and biases are propagated from inputs to output is called forward propagation. After arriving at the predicted output, the loss for the training example is calculated. This left-to-right process for a single example is represented in the computation graph below (recall that the prediction &lt;em&gt;y_hat&lt;/em&gt; equals &lt;em&gt;A&lt;/em&gt;):
&lt;img src=&#34;forward-prop.png&#34; alt=&#34;forward-prop&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;backward-propagation&#34;&gt;Backward Propagation&lt;/h3&gt;
&lt;p&gt;We previously saw how the gradient descent algorithm allows us to find the minimum of the cost function. Back propagation is the process of calculating the partial derivatives from the loss function back to the inputs, thereby updating the values of w and b that lead us to the minimum. It’s helpful writing out the partial derivatives starting from &lt;em&gt;dA&lt;/em&gt; to see how to arrive at &lt;em&gt;dw&lt;/em&gt; and &lt;em&gt;db&lt;/em&gt;. Using the chain rule of calculus yields:
&lt;img src=&#34;chain-rule.png&#34; alt=&#34;chain-rule&#34;&gt;
This right-to-left process that results in updated parameters w and b is represented in the computation graph below, where the results of the derivations are shown:
&lt;img src=&#34;back-prop.png&#34; alt=&#34;back-prop&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;prediction&#34;&gt;Prediction&lt;/h3&gt;
&lt;p&gt;After finding the optimal values of &lt;em&gt;w&lt;/em&gt; and &lt;em&gt;b&lt;/em&gt; after a certain number of iterations, the next step is to use those values to calculate the final predicted output. The sigmoid activation function yields a probability distribution between 0 and 1 — for logistic regression we need to convert that to a discrete value of either 0 or 1. To do so, we’ll apply a threshold value to the output, 0.5 for instance, so that probability values 0.5 or above result in a predicted output value of 1, whereas probability values less than 0.5 result in a predicted output value of 0.&lt;/p&gt;
&lt;p&gt;After predicting the final output, we need to see how well the model did. One way to evaluate classification models is by defining a term called accuracy. It’s the fraction of the predictions that our model got right:
&lt;img src=&#34;accuracy.png&#34; alt=&#34;accuracy&#34;&gt;
The figure below summarizes the iterative process through which the machine learns:
&lt;img src=&#34;model-train.png&#34; alt=&#34;overall training&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;practical-example&#34;&gt;Practical Example&lt;/h2&gt;
&lt;p&gt;Alright, enough theory, time for application! Remember the cat vs. dog classification problem — given an image of either a cat or a dog, will the computer be able to classify it as one or the other? Let’s implement a single layer neural net representation of logistic regression from scratch using Python. We’ll use Kaggle’s dogs vs. cats dataset and build the model step by step: I’ve created a &lt;a href=&#34;https://github.com/jissac/ScratchML&#34;&gt;Github repository called ScratchML that contains the CatsvsDogs_Logistic_Regression Jupyter notebook&lt;/a&gt;. We’ll go through preparing and pre-processing the data (often the most time-consuming part of the journey) and then define and run our model. Try to understand what each method does and how the formulas above are being implemented. Then re-write them yourself in order to build your intuition.
After training and running the model, our humble representation of logistic regression managed to get around 69% of the test set correctly classified — not bad for a single layer neural network! Using cutting edge architectures will yield world-class results — but they are built using much of the same principles we learned implementing logistic regression.&lt;/p&gt;
&lt;h2 id=&#34;now-what&#34;&gt;Now what?&lt;/h2&gt;
&lt;p&gt;As is the nature of learning, we’ve only scratched the surface. We’ve covered a general overview of the major concepts, but there are yet many more topics to learn such as implementing regularization to prevent overfitting of the data, other activation functions (ReLU, tanh, etc.), stochastic gradient descent (SGD), k-fold cross validation, to name a few.&lt;/p&gt;
&lt;p&gt;I’ve put together a &lt;a href=&#34;https://github.com/jissac/Machine-Learning-Resources&#34;&gt;list of machine learning resources&lt;/a&gt; that should get you started on your journey. Keep learning and implementing what you learn, after all, it’s an iterative process! Happy descent — may you reach the optimum point! :)&lt;/p&gt;
&lt;h2 id=&#34;resources&#34;&gt;Resources:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.deeplearningbook.org/contents/optimization.html&#34;&gt;http://www.deeplearningbook.org/contents/optimization.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.coursera.org/learn/neural-networks-deep-learning&#34;&gt;https://www.coursera.org/learn/neural-networks-deep-learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://cs231n.github.io/neural-networks-1/&#34;&gt;http://cs231n.github.io/neural-networks-1/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://stats.stackexchange.com/questions/213325/neural-network-meaning-of-weights&#34;&gt;https://stats.stackexchange.com/questions/213325/neural-network-meaning-of-weights&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://stackoverflow.com/questions/2480650/role-of-bias-in-neural-networks&#34;&gt;https://stackoverflow.com/questions/2480650/role-of-bias-in-neural-networks&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Keep Your Eyes Where You Want to Go, and Other Life Lessons I&#39;ve Learned from Motorcycling</title>
      <link>https://jamesis.me/post/moto/</link>
      <pubDate>Fri, 30 Sep 2016 22:21:31 -0500</pubDate>
      <guid>https://jamesis.me/post/moto/</guid>
      <description>&lt;p&gt;&amp;ldquo;Look through the curve!&amp;rdquo; the instructor barked over the noise of motorcycle engines. I revved the throttle and looked ahead as I blazed past the cones. Here I was, clinging on for dear life and trying to pass the road test.  Was I going too fast? I glanced down at the speedometer.&lt;/p&gt;
&lt;p&gt;7 mph&amp;hellip;&lt;/p&gt;
&lt;p&gt;Everything&amp;rsquo;s faster on a motorcycle.&lt;/p&gt;
&lt;p&gt;Last year I learned how to ride. As I look back on those early days when motorcycling seemed so unfamiliar and scary, I appreciate the small steps that have made me a more confident and seasoned rider. And as a firm believer in the value of connecting the dots and learning from different experiences, here are some life lessons that motorcycling has taught me:&lt;/p&gt;
&lt;h2 id=&#34;get-trained&#34;&gt;Get Trained&lt;/h2&gt;
&lt;p&gt;Before I rode off into any sunsets, I needed to know how to operate a motorcycle. Taking the Motorcycle Safety Foundation (MSF) course was essential in starting my journey; here I was able to practice on loaner bikes and have watchful eyes monitor my progress.&lt;/p&gt;
&lt;p&gt;Similarly, when starting any new endeavor, it&amp;rsquo;s important to learn the correct things. My buddy Mark likes to say, &amp;ldquo;It ain&amp;rsquo;t what you don&amp;rsquo;t know that gets you into trouble. It&amp;rsquo;s what you know for sure that just ain&amp;rsquo;t so&amp;rdquo;. Getting taught by great teachers and mentors, whether they be people (dead or alive), books, courses, etc. is essential to make sure you unlearn any prior misconceptions and have a solid foundation upon which to build.&lt;/p&gt;
&lt;p&gt;What&amp;rsquo;s something you&amp;rsquo;ve wanted to learn or get good at? Have you spent time and money to get trained? (And if you&amp;rsquo;re contemplating joining a biker gang, I highly suggest you take the MSF course first.)&lt;/p&gt;
&lt;h2 id=&#34;get-well-equipped&#34;&gt;Get Well-Equipped&lt;/h2&gt;
&lt;p&gt;&amp;ldquo;ATGATT: All The Gear All The Time&amp;rdquo;. This is a mantra that wise motorcyclists recite before mounting their steely steeds. And wisely so. There is inherent risk in motorcycling. No metal cage protects you (consequently, car riders are referred to as &amp;lsquo;cagers&amp;rsquo; in the motorcycle community). Enter helmet, armored leather jacket, gloves, and sturdy boots. Sure, I may look like a Power Ranger when I ride, but then again, I&amp;rsquo;ve worked hard to cultivate my well-moisturized skin and chiseled physique. Being properly outfitted helps me concentrate and enjoy the riding experience that much more, knowing that I&amp;rsquo;m doing my best to ride safe.&lt;/p&gt;
&lt;p&gt;So in whatever you do, whether it&amp;rsquo;s learning to play the guitar or to paint, having the right tools makes the entire experience more enjoyable. Buying a cheap guitar that has terrible intonation will only add to your frustrations as you begin. Having high quality brushes might not make you the next van Gogh, but it will certainly keep your mind focused on what matters most - creating good paintings.&lt;/p&gt;
&lt;h2 id=&#34;have-a-support-circle&#34;&gt;Have a Support Circle&lt;/h2&gt;
&lt;p&gt;Something about motorcycles - the associated thrill and independence, the link between man and machine - captures my attention. On the road, it’s just you and your bike. However, I&amp;rsquo;ve also learned that motorcycling is a very tribe-based experience. There&amp;rsquo;s even something called the Secret Motorcycle Wave (SMW): whenever oncoming bikers pass each other on the road, they flash a salute of sorts, a casual-cool wave that signifies, &amp;lsquo;Hey bruh (or sis), I identify with you&amp;rsquo;. It&amp;rsquo;s a fascinating feeling, flashing the SMW to my brothers and sisters as I ride, my heart swelling with camaraderie-induced pride.&lt;/p&gt;
&lt;p&gt;Also, friends have been essential in my riding experience. My riding friends helped me overcome my initial fears and challenged me to not become satisfied riding down the same old roads. Good friends inspire you to try and accomplish things you never thought you could do. Find people like that and befriend them (likewise, strive to become an encouraging friend). Your life will become fuller as you share memorable experiences in community.&lt;/p&gt;
&lt;h2 id=&#34;achieve-small-victories&#34;&gt;Achieve Small Victories&lt;/h2&gt;
&lt;p&gt;I recently biked around Lake St. Claire, traveling from Michigan to Canada on my longest motorcycle trip yet. For me, that was a milestone - a culmination of the small victories I&amp;rsquo;d achieved like graduating past practicing in the parking lot, getting comfortable with road and highway speeds, learning to take corners safely, and internalizing the principles I&amp;rsquo;d learned in the MSF course.&lt;/p&gt;
&lt;p&gt;Long ago, the philosopher Lao Tzu philosophized, &amp;ldquo;The journey of a thousand miles begins with a single step.&amp;rdquo; Sometimes I unduly focus on the distance separating me from a goal and I forget to appreciate the steps I&amp;rsquo;ve already taken. And in a culture where mostly big victories are celebrated, perhaps we should be more kind to ourselves and learn to give thanks for the small wins. Being mindful of keeping one foot in front of the other while staying aware of the bigger vision is something I&amp;rsquo;m trying to improve at, which brings me to the final point:&lt;/p&gt;
&lt;h2 id=&#34;keep-your-eyes-where-you-want-to-go&#34;&gt;Keep Your Eyes Where You Want to Go&lt;/h2&gt;
&lt;p&gt;On a motorcycle, your eyes are one of your most valuable assets. Where you look is where you go. The flip side to that is called target fixation: the tendency to focus so much attention on an object that you increase your risk of colliding with it. The solution to target fixation is to widen your perspective and look further ahead. By broadening your viewing area, the slower things seem to move, allowing you to be aware of more potential hazards and opportunities.&lt;/p&gt;
&lt;p&gt;Taking the time to write down what you really want out of life is important. Being mindful of your aspirations in different life areas relating to your body, emotions, relationships, finances, and spirituality will help you steer your time and energy wisely. I encourage you to write them out, as the very act of writing and seeing your goals with your eyes is like taking that first step.&lt;/p&gt;
&lt;p&gt;On a motorcycle and in life, your body naturally wants to go in the direction you are looking. So where are you focusing your gaze? Remember, where you look is where you go. I wish you a safe and exciting journey.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Magnífico Ecuador</title>
      <link>https://jamesis.me/post/ecuador/</link>
      <pubDate>Sat, 11 Jul 2015 22:21:31 -0500</pubDate>
      <guid>https://jamesis.me/post/ecuador/</guid>
      <description>&lt;p&gt;Hola! Ecuador es un pais magnifico! I went backpacking with my friends and experienced the sights and culture of Ecuador. Check out the video below!&lt;/p&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/vH_ZHe8lX0M&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

</description>
    </item>
    
    <item>
      <title>White Water Rafting</title>
      <link>https://jamesis.me/post/rafting/</link>
      <pubDate>Wed, 03 Sep 2014 22:21:31 -0500</pubDate>
      <guid>https://jamesis.me/post/rafting/</guid>
      <description>&lt;p&gt;Some friends and I went rafting on the Lower New River Gorge and Upper New River Canyon. Got some zip-lining and disc golf in as well. Check out the video I made below!&lt;/p&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/5hV_qh06Tjc&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

</description>
    </item>
    
    <item>
      <title>Niagara: Untamable Beauty</title>
      <link>https://jamesis.me/post/niagara/</link>
      <pubDate>Wed, 02 Jul 2014 21:02:31 -0500</pubDate>
      <guid>https://jamesis.me/post/niagara/</guid>
      <description>&lt;p&gt;I had always heard about the Falls. But like so many before me, I truly understood the Falls only by standing right next to the crashing waters, its majestic roar and unbridled power engulfing my senses. As I stood there, water splashing over me and mist covering my body, I couldn’t help but close my eyes and simply allow myself to be overwhelmed. Water. So tame when coming out of the faucet into my hands. So fierce and uncontainable here in this moment.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;rainbow.jpg&#34; alt=&#34;nia2&#34;&gt;&lt;/p&gt;
&lt;p&gt;As I look back, the two words that Niagara invoke are: beauty and power. Sunbeams reflecting off the mist produce glistening rainbows (and yes, even double rainbows) over the waters. Niagara is a very sensory experience. Sight. Sound. Touch. Close your eyes and you hear the roar of thousands of lions. Open them and you see the wonderful handiwork of receding glaciers from ages past.&lt;/p&gt;
&lt;p&gt;I wonder what the first humans to stumble upon the mighty Falls felt. Their response must have been similar to mine: silent awe. Granted, Niagara is much more commercialized now. However, take away everything except the rushing waters and it’s hard to imagine even the most jaded person having any other response. Niagara has that special ‘something’. And this ‘something’ plucks at my heartstrings. A yearning for adventure, for a land far, far away, for things I can’t quite articulate.&lt;/p&gt;
&lt;p&gt;Perhaps that’s what beauty does to you:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;It renders you speechless.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;niagara2.jpg&#34; alt=&#34;nia3&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Tulip-Time!</title>
      <link>https://jamesis.me/post/tulips/</link>
      <pubDate>Mon, 05 May 2014 21:02:31 -0500</pubDate>
      <guid>https://jamesis.me/post/tulips/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Springtime!&lt;/strong&gt; This past winter was one of the most brutal winters in the history of Michigan winters.  It was a winter inside a winter. Fortunately, even unending winters eventually come to an end. So you can imagine my delight when the first blades of grass began poking their green, hopeful heads out into the world above. A frostbitten land was in desperate need of warmth and color.&lt;/p&gt;
&lt;p&gt;Every year in Holland, MI millions of tulips burst forth in bloom. In perfect time, the tulips unfurl their petals as if to tell the world, “Hold on, there is still a hope left in this barren land. Spring is here!” And so it was with hopeful hearts that some friends and I trekked out to Holland, eager to see the storied tulip town. Holland has a rich Dutch heritage and the streets were filled with people in traditional Dutch garb.&lt;/p&gt;
&lt;p&gt;We walked around the Marktplaatz, a 19th-century styled marketplace filled with vendors sharing crafts and selling Dutch food. There was a shoemaker demonstrating the construction of wooden clogs, the traditional Dutch footwear. We walked around the quaint town imagining how life must have been like in the Netherlands so many long years ago.&lt;/p&gt;
&lt;p&gt;And to top it all off, we ate street-side fried funnel cake, fried Oreos, fried cheesecake, and fried snickers (though I somewhat doubt such delicacies were available back then). Yes, it was a great day to be healthy.&lt;/p&gt;
&lt;p&gt;But the real stars of the day were of course, the tulips. Arrayed in numerous sizes and colors like an army of multicolored soldiers, the tulips swayed in the gentle afternoon breeze. The looked cool and they knew it. Such confidence.&lt;/p&gt;
&lt;p&gt;In fact, &lt;strong&gt;when I grow up I want to exude confidence and hope like those tulips.&lt;/strong&gt; Worthy life goal?&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;lighthouse.jpg&#34; alt=&#34;tulips2&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>NYC: Lights, People, Action</title>
      <link>https://jamesis.me/post/nyc/</link>
      <pubDate>Tue, 22 Apr 2014 21:02:31 -0500</pubDate>
      <guid>https://jamesis.me/post/nyc/</guid>
      <description>&lt;p&gt;What can I say about New York City that hasn’t already been said? These lights will make you feel brand new, these streets will inspire you. You get the drift. This is a city filled with movement and magic. I knew all this in my head, but actually going there and basking under the glow of a million LEDs in Times Square opened my eyes. I have gone from darkness into light. Bright, beautiful light.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;times-square.jpg&#34; alt=&#34;nyc1&#34;&gt;&lt;/p&gt;
&lt;p&gt;And then there’s the people: wave after wave of tourists, native New Yorker’s, dreamers, wanderers, celebrities, bottom-dwellers, and everyone in between. I felt energized amidst this constant throb of people and their energy. At the same time, I realized how easy it is to feel alone in a crowd. People are so engrossed in their own lives and calendars that everything else blurs, becoming a casualty of their busyness. Granted, we all get caught up and blinded by our own agendas, but in New York, everything is amplified.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;street-musician.jpg&#34; alt=&#34;nyc2&#34;&gt;&lt;/p&gt;
&lt;p&gt;Speaking of amplification, there are so many good musicians here in NYC! Subway musicians who can give pop-stars music lessons sing their mellifluous tunes to whoever might lend a ear (and a few dollars). I love that about cities: there’s so much talent just waiting to be found. Who knows, that girl sitting next to you on the subway might be an accomplished Broadway singer.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;central-park.jpg&#34; alt=&#34;nyc3&#34;&gt;&lt;/p&gt;
&lt;p&gt;One of my favorite experiences in the city was biking around Central Park. Now, Central Park is like an oasis in the middle of a desert. Juxtaposed between the concrete jungle and rising skyscrapers are trees and lakes. Here, time slows down, if only for a moment; it’s a stark contrast to the hubbub of Times Square. There are people napping, strolling, biking, and just plain relaxing. The weather was perfect, with the sun shining gently and a gentle breeze whispering softly. Basking in the glorious outdoors while riding in the wind and seeing the city’s outline peek through the trees was a surreal experience.&lt;/p&gt;
&lt;p&gt;Well, I must seem like a NYC fanboy by now; the city certainly lured me in with its siren song. Give it a try and experience it for yourself. This city might very well surprise and inspire you.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;manhattan.jpg&#34; alt=&#34;nyc4&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>DC: The Cherry Blossom Festival</title>
      <link>https://jamesis.me/post/dc/</link>
      <pubDate>Thu, 17 Apr 2014 21:02:31 -0500</pubDate>
      <guid>https://jamesis.me/post/dc/</guid>
      <description>&lt;p&gt;In 1912, Mayor Yukio Ozaki of Tokyo gifted 3,000 cherry trees to the city of Washington, DC as a sign of friendship between the US and Japan. Today, the National Cherry Blossom Festival attracts more than a million people each year who come from all over the world to admire the flowering cherry trees.&lt;/p&gt;
&lt;p&gt;In light of this amazing history, a few friends and I decided to travel to DC and experience the cherry blossom bloom first-hand. It was packed! I’ve visited DC before, but this time, the city was overflowing with people. We had to wait over an hour just to get a sandwich from a food-truck. But being able to share this moment with so many people as we all enjoyed the blooming trees was surreal. My favorite part was watching the sun set over the Potomac River (pictured above), its golden beams dancing in between the blossoming cherry trees.&lt;/p&gt;
&lt;p&gt;How do you respond when you encounter beauty in something as simple as a flowering tree? Perhaps all you can do is simply be in awe.&lt;/p&gt;
&lt;p&gt;Thank you Japan for this beautiful, living memorial.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;dc.jpg&#34; alt=&#34;dc&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Pittsburgh: City of Bridges</title>
      <link>https://jamesis.me/post/pittsburgh/</link>
      <pubDate>Fri, 11 Apr 2014 21:02:31 -0500</pubDate>
      <guid>https://jamesis.me/post/pittsburgh/</guid>
      <description>&lt;p&gt;Spontaneous road trips are sometimes needed to jolt one out of the rhythm of the regular work week. So one weekend, that’s what some friends and I decided to do: travel to Pittsburgh on a whim. We left Michigan on Friday night after work, ate Potbelly sandwiches in the car, and slept all the way to Pittsburg. Well, only the passengers slept, thankfully. I had gotten a rough itinerary of fun things to do from my friend who studied at Carnegie Mellon and our dear friend Google had also given helpful suggestions, so we were set. As a side bonus, the majority of the movie ‘The Dark Knight Rises’ was filmed in Pittsburgh, so I was excited to see the city firsthand.&lt;/p&gt;
&lt;p&gt;Our day started on Saturday. We visited the Strip District, a one-half square mile area filled with street vendors and open-air farmers markets. After stuffing our faces at Pamela’s Diner we waddled around for a bit before setting out to take in the sites of the city. We explored the University of Pittsburgh and its historic looking buildings, napped in the Cathedral of Learning (knowledge transfer by diffusion anyone?), and looked over the city from Mount Washington (pictured above). It had been overcast the whole day and started raining in the evening. Something about rainy days calls for Thai food, so we looked on Yelp, found the restaurant Smiling Banana Leaf and satisfied our cravings. The rest of the night was spent hanging out and playing various board games in our hotel room.&lt;/p&gt;
&lt;p&gt;Driving back on Sunday afternoon, I started thinking about the trip. It’s so interesting to see people live out their lives in a different part of the country. It takes you out of your bubble, out of your mundane routine, out into the lives of other people. Perhaps that’s why I enjoy going to new places: life isn’t just about me, even though I so often think it is. Life is about people and relationships. Life is about living in vibrant color with new experiences and discovery. Life is about bridging the gap between who you are and who you want to be. Alright, I’ll stop with the cheesy (genius?) sayings. Go take a spontaneous trip. Peace!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Learning to Fall</title>
      <link>https://jamesis.me/post/skiing/</link>
      <pubDate>Fri, 21 Mar 2014 21:02:31 -0500</pubDate>
      <guid>https://jamesis.me/post/skiing/</guid>
      <description>&lt;p&gt;The first time I went skiing was at Mt. Brighton (pictured above). Now, seasoned skiers might chuckle at these rounded slopes, but for a first-timer like me, these hills looked like the Himalayan peaks. And indeed, although I had watched countless YouTube videos about skiing the week before, the moment I buckled up the rented boots to the skis, my meticulous research and mental preparation melted away.&lt;/p&gt;
&lt;p&gt;I signed up for beginners lessons with my group and after learning the basics we proceeded to conquer the beginner bunny slope. To get up this slope there was something called the ‘magic carpet’, which is an automated conveyor belt carrying skiers to the top. I lined up behind the jockeying 5-year-olds and waited. This was it. I closed my eyes and imagined the view from atop the bunny hill. I opened my eyes just in time to see that I was next in line. Too bad I slid onto the magic carpet, lost my balance, and saw the laughing blue sky above me&amp;hellip;&lt;/p&gt;
&lt;p&gt;Well, after such an accomplishment, how could I quit? And indeed, I learned how to fall a thousand different ways that day. After several hours, I graduated to some of the more difficult slopes. I think I just needed to get used to the fact that I was traveling fast - to get over my fear of this unfamiliar experience. And though I fell in the silliest of ways, each fall prompted me to ask myself &amp;ldquo;What can I do differently?&amp;quot;. After all, according to my buddy T. Edison, “I have not failed. I’ve just found 10,000 ways that won’t work.”&lt;/p&gt;
&lt;p&gt;Therefore, in the spirit of discovery and trying new things, here are four lessons I&amp;rsquo;m learning about growing from experiences and not fearing failure. Hopefully you can also apply these to your life and business:&lt;/p&gt;
&lt;h2 id=&#34;1-fear-is-a-friend-whos-misunderstood&#34;&gt;1. Fear is a Friend Who&amp;rsquo;s Misunderstood&lt;/h2&gt;
&lt;p&gt;In the song &amp;lsquo;Heart of Life&amp;rsquo;, John Mayer sings the lyric above. While fear often debilitates, perhaps shifting our perspective on fear changes it from an enemy to a &amp;lsquo;friend&amp;rsquo;? So often we spend our lives running away from fear. What if we instead slowed down to understand what fear is revealing about ourselves? Fear of going fast on the slopes stopped me from going further. The shift in perspective -making speed my friend - allowed me to change my mindset and tweak my technique. It was then that I started enjoying the experience and achieving.&lt;/p&gt;
&lt;p&gt;Think about it from a life perspective as well. What fears are subconsciously, yet deliberately causing you to fall or keeping you from moving forward? Realizing that will enable you to experience life adventurously.&lt;/p&gt;
&lt;h2 id=&#34;2-try-new-experiences&#34;&gt;2. Try New Experiences&lt;/h2&gt;
&lt;p&gt;Growth comes from progress and progress comes from trying new things. Fear often confines us to the familiar. After all, you may ask, if you&amp;rsquo;ve been successful in one area, why risk losing a good thing by branching out? Therein lies the subtle error. Living life solely in maintenance mode robs us of our inherent creativity. Trying something different, whether it be learning an instrument, starting a new business venture, or even drinking green tea instead of the usual morning coffee resets our penchant for familiarity. The reason I decided to try skiing was to learn a new skill. In doing so I made new friends and learned so much about myself. And that&amp;rsquo;s the beauty of being adventurous. It doesn&amp;rsquo;t require scaling Mt. Everest or colonizing Mars, noble pursuits as those are, to feel accomplished. Simply being willing to wander outside the picket fence starts us on a journey.&lt;/p&gt;
&lt;h2 id=&#34;3-embrace-failure&#34;&gt;3. Embrace Failure&lt;/h2&gt;
&lt;p&gt;Failing is hard. Failing hurts. Falling hurts too. If you follow steps 1 and 2 above, you will get yourself into situations where you&amp;rsquo;re uncomfortable. But that&amp;rsquo;s OK! When I&amp;rsquo;d fallen for the umpteenth time, unable to distinguish between the wet snow on my face from the tears of frustration, I was really tempted to take off my ski gear and head to the warmth of the lodge. But looking back on the experience, I&amp;rsquo;m glad I didn&amp;rsquo;t. Isn&amp;rsquo;t that how life is? In the moment, embracing failure sounds so repugnant. But I&amp;rsquo;m not saying wallow in your mistakes; rather, learn from them. When you&amp;rsquo;re at your lowest, when your feelings condemn you, when frustrations outnumber the hairs on your head, when you&amp;rsquo;re surrounded by thoughts of insufficiency, take time to sit in silence. This moment is crucial: how you respond when you&amp;rsquo;re down determines the kind of person you are becoming. Write down your thoughts, the positive and the negative. What you do next will determine your success, which brings us to the final point:&lt;/p&gt;
&lt;h2 id=&#34;4-ask-the-right-questions&#34;&gt;4. Ask the Right Questions&lt;/h2&gt;
&lt;p&gt;The quality of your questions determines the quality of your answers. Ask and you will receive. Instead of fostering an internal dialogue of &amp;ldquo;How come I always fail?&amp;rdquo; or &amp;ldquo;Why do bad things happen to me?&amp;rdquo; which only result in negative internal answers like, &amp;ldquo;Because you&amp;rsquo;re a failure!&amp;rdquo; or &amp;ldquo;You&amp;rsquo;re just an unlucky loser&amp;rdquo;, we must cultivate the habit of asking empowering questions. Questions like &amp;ldquo;What can I learn from this experience?&amp;rdquo; and &amp;ldquo;How can I break this problem into doable steps?&amp;rdquo; re-focus our attention on solutions. In times of failure, I&amp;rsquo;m often my own worst critic. Instead of getting caught in an endless feedback loop of self-pity, I find that re-framing the problem as a question gets me thinking in the right direction.&lt;/p&gt;
&lt;p&gt;Once you start ideating empowering answers, act on them. It&amp;rsquo;s the momentum generated from positive action, no matter how small, that propels you towards success. And if the recent popularity of the game Flappy Birds has taught me anything, it’s that sometimes, in order to go further, we must learn how to fall.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;flappy-bird.png&#34; alt=&#34;flappy&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>My First Stop-Motion Whiteboard Animation</title>
      <link>https://jamesis.me/post/stop_motion/</link>
      <pubDate>Fri, 14 Mar 2014 00:31:33 -0500</pubDate>
      <guid>https://jamesis.me/post/stop_motion/</guid>
      <description>
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/gSDINr23mwI&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;When my friend Aiswarya told me about a video contest held by the National Academy of Engineering in commemoration of their 50th anniversary, I knew I had to do it. The goal was to make a video highlighting engineering innovations and how they enhance quality of life and serve society. Only problem was, the deadline was a week away (since we discovered the contest late). But I’ve always been interested in making videos, so I accepted the challenge. I had previously seen whiteboard animations on YouTube and wanted to try my hand at it, so I decided on the medium for the video.&lt;/p&gt;
&lt;p&gt;For the theme, I wanted to show how technology has helped people connect over the years. From the typewriter to the computer to cell phones and apps to the growing potential of virtual/augmented reality, great technology always bridges the gap between people — allowing us to empathize with each other. After all, I think one of a person’s deepest desires is not so much to be fixed as it is to be understood. So I wanted to capture the connection and closeness that technology allows.&lt;/p&gt;
&lt;p&gt;I already had a whiteboard, markers, and camera. I borrowed a tripod from my friend Tianbo and completed my setup (pictured above). So on a Wednesday (March 26th) evening I started, hoping I could finish by the Monday (March 31st ) deadline. I whispered a prayer for drawing skills and creativity, took a black dry-erase marker in hand, and started.&lt;/p&gt;
&lt;p&gt;The drawing and photography took till the end of Saturday (I now sympathize with and greatly admire the animators who breathed life into my favorite classic Disney animations). Then I needed to work on the soundtrack. I took my guitalele and looped 4 chords into the recording software. I timed the music tempo to match the video frame rate and started adding other sonic layers to the soundtrack. Music comes easier to me than drawing, so I was able to finish the soundtrack on Sunday afternoon.&lt;/p&gt;
&lt;p&gt;Finally, it was time to edit the pictures and make the video. Since I didn’t have Lightroom to batch edit,I had to edit the pictures individually in Photoshop (next time I will definitely not do that!). But time was scarce and this had to be done, so I created some shortcuts in Photoshop to make editing easier and got to work. A couple of hours later, I was done (albeit bleary-eyed and exhausted). I sent the video to my friends for a final look-through and passed out. I submitted the video on Monday evening; what a satisfying feeling!&lt;/p&gt;
&lt;p&gt;Completing this video was an exercise in endurance; by the grace of God I was able to finish in time with a video I’m proud of. Having time to spend on the project only after work and on the weekend meant I had to be efficient. Since I had never done anything like this before, I didn’t know if it was possible to complete a stop-motion video in less than a week. But sometimes, not knowing the line between ‘possible’ and ‘not possible’ helps you attempt and do the impossible. At least that’s how I felt after finishing!&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;ani_setup.jpeg&#34; alt=&#34;animation setup&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
